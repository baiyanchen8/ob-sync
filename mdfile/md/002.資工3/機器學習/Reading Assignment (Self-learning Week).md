---
title: Reading Assignment (Self-learning Week)

---

# HuggingGPT 報告
## 摘要
在追求人工通用智慧的過程中，解決涉及不同領域和模式的複雜任務是一個重要的步驟。雖然有豐富的人工智慧模型可用於不同領域和模式，但它們無法應對複雜的人工智慧任務。考慮到大型語言模型（LLMs）在語言理解、生成、互動和推理方面的優越能力，我們主張LLMs可以充當控制器，管理現有的人工智慧模型以解決複雜的人工智慧任務，而語言可以成為通用界面以實現這一點。基於這一理念，我們提出了 HuggingGPT，這是一個利用LLMs（例如 ChatGPT）連接機器學習社區中各種人工智慧模型（例如 Hugging Face）來解決人工智慧任務的框架。具體而言，我們使用 ChatGPT 在接收用戶請求時進行任務規劃，根據 Hugging Face 中提供的模型描述選擇模型，使用所選的AI模型執行每個子任務，並根據執行結果總結響應。通過利用 ChatGPT 的強大語言能力和 Hugging Face 中豐富的AI模型，HuggingGPT能夠涵蓋多種不同模式和領域的複雜AI任務，並在語言、視覺、語音和其他具有挑戰性的任務中取得令人印象深刻的成果，為實現人工通用智慧開辟了一條新途徑。

## 引言
### 背景和動機
近年來，大型語言模型（LLMs）如 ChatGPT 受到學術界和工業界的關注，由於它們在各種自然語言處理（NLP）任務上的卓越性能。基於大規模預訓練和從人類反饋中獲取強化學習的LHF \[2]，LLMs在語言理解、生成、互動和推理方面展現出卓越的能力。LLMs的強大能力也推動了許多新興的研究主題（例如，上下文學習 \[1, 7, 8]，指導學習 \[9, 10, 11, 12, 13, 14]，以及思維鏈提示 \[15, 16, 17, 18]），進一步探討了LLMs的巨大潛力，為我們構建先進的人工智慧系統帶來了無限的可能性。儘管取得了巨大的成功，當前LLM技術仍然不完善，面臨著在構建先進AI系統的過程中的一些緊迫挑戰。我們從以下幾個方面討論了這些挑戰：1）受限於文本生成的輸入和輸出形式，當前LLMs在處理視覺和語音等複雜信息方面缺乏能力，儘管它們在NLP任務上取得了顯著的成就；2）在現實場景中，一些複雜任務通常由多個子任務組成，因此需要多個模型的協作和調度，這也超出了語言模型的能力範圍；3）對於一些具有挑戰性的任務，LLMs在零次或少次設置中表現出色，但它們仍然不如一些專家（例如，微調模型）強大。如何解決這些問題可能是LLMs邁向人工通用智慧的關鍵一步。

在本文中，我們指出，為了處理複雜的AI任務，**LLMs應該能夠與外部模型協作，利用它們的力量**。因此，**關鍵問題是如何選擇合適的中間件來在LLMs和AI模型之間搭建連接**。為解決這個問題，我們注意到每個AI模型都可以以語言形式描述，概括其功能。因此，我們引入了一個概念：“語言是LLMs連接AI模型的通用界面”。換句話說，通過將這些模型描述結合到提示中，LLMs可以被視為管理AI模型的大腦，進行規劃、調度和協作。因此，這種策略使LLMs能夠調用外部模型來解決AI任務。然而，當涉及將多個AI模型集成到LLMs中時，另一個挑戰浮現：解決眾多AI任務需要收集大量高質量的模型描述，這反過來需要進行大量的提示工程。巧合的是，我們注意到一些公共的機器學習社區通常提供豐富的應用模型，並為解決特定的AI任務（如語言、視覺和語音等）提供了明確的模型描述。這些觀察為我們帶來了一些靈感：我們是否可以通過語言界面將LLMs（例如ChatGPT）與公共機器學習社區（例如GitHub、Hugging Face等）鏈接起來，以解決通過語言界面進行複雜AI任務的問題？

因此，在本文中，我們提出了一個名為HuggingGPT的系統，用於將LLMs（即ChatGPT）和機器學習社區（即Hugging Face）相連，該系統可以自主處理來自不同模態的輸入並解決眾多複雜的AI任務。具體來說，對於Hugging Face中的每個AI模型，我們使用其來自庫的相應模型描述，將其融入提示中以與ChatGPT建立連接。然後，在我們的系統中，LLMs（即ChatGPT）將充當大腦，決定用戶問題的答案。整個HuggingGPT的過程可以分為四個階段：

<img src="image/S11hg8wBa.png" width="9999" height="">


- 任務規劃：使用ChatGPT分析用戶的請求，理解其意圖，通過提示將其解構為可能的可解決任務。
- 模型選擇：為了解決計劃的任務，ChatGPT根據Hugging Face中提供的模型描述，選擇適用的專家模型。
- 任務執行：調用並執行每個選定的AI模型，將結果返回給ChatGPT。
- 響應生成：最後，ChatGPT用於整合所有模型的預測並為用戶生成響應。通過這種設計，HuggingGPT可以自動從用戶請求生成計劃，並使用外部模型，因此可以集成多模態的感知能力並處理多個複雜的AI任務。值得注意的是，這種流水線還允許HuggingGPT繼續吸收來自特定任務專家的能力，實現可增長和可擴展的AI能力。此外，我們還指出，任務規劃在HuggingGPT中起著非常重要的作用，直接決定後續工作流程的成功。因此，如何進行計劃也是評估LLMs能力的一個良好角度，這也為LLMs評估開啟了一扇新的大門。
:::spoiler example
![image](B1ncz8PST.png)
:::

總的來說，我們的貢獻可以總結如下：

為了補充大型語言模型和專家模型的優勢，我們提出了具有模型合作協議的HuggingGPT。 HuggingGPT將LLMs應用為規劃和決策的大腦，並自動調用和執行每個特定任務的專家模型，為設計通用AI解決方案提供了新的途徑。

通過將Hugging Face中的模型與ChatGPT周圍的許多特定任務模型集成，HuggingGPT能夠應對多模態和多領域的通用AI任務。通過模型的開放協作，HuggingGPT可以為用戶提供多模態且可靠的對話服務。

我們指出在HuggingGPT（和自主代理）中，任務規劃的重要性，並制定了一些用於測量LLMs在規劃方面能力的實驗評估。

在多個具有挑戰性的AI任務（包括語言、視覺、語音和跨模態）上的大量實驗展示了HuggingGPT在理解和解決多模態和多領域的複雜任務方面的能力和巨大潛力。

## 相關工作
在近年來，自然語言處理（NLP）領域已經被大型語言模型（LLMs）的出現所改變，這些模型包括GPT-3 [1]、GPT-4 [20]、PaLM [3]和LLaMa [6]等。LLMs在零次和少次設置的任務中展示出令人印象深刻的能力，以及在數學問題和常識推理等更複雜任務中的能力，這歸功於它們龐大的語料庫和密集的訓練計算。為了擴大大型語言模型（LLMs）的應用範圍，當前的研究可以分為兩個分支：
1. 一些工作設計了統一的多模態語言模型，以解決各種人工智慧任務[21, 22, 23]。例如，Flamingo [21]結合了凍結的預訓練視覺和語言模型，用於感知和推理。BLIP-2 [22]使用Q-former來協調語言和視覺語義，Kosmos-1 [23]將視覺輸入合併到文本序列中，以融合語言和視覺輸入。
2. 最近，一些研究人員開始研究在LLMs中使用工具或模型的整合[24, 25, 26, 27, 28]。Toolformer [24]是首個在文本序列中引入外部API標籤的工作，有助於LLMs訪問外部工具的能力。因此，許多研究已經擴展LLMs以包含視覺模態。Visual ChatGPT [26]將視覺基礎模型（例如BLIP [29]和ControlNet [30]）與LLMs融合。Visual Programming [31]和ViperGPT [25]將LLMs應用於視覺對象，使用編程語言將視覺查詢解析為可解釋的Python代碼步驟。

與這些方法不同，我們提出的HuggingGPT朝著更通用的AI能力邁出了更大的一步：

1. HuggingGPT將LLMs應用為界面，將用戶請求路由到專家模型，有效地結合了LLMs的語言理解能力和其他專家模型的專業知識。

2. HuggingGPT不僅限於視覺感知任務，而且通過在LLMs之間組織協作，可以處理任何模態或任何領域的任務。由於HuggingGPT中的任務規劃的設計，我們的系統可以自動且有效地生成任務程序，解決更複雜的問題。

3. HuggingGPT提供了更開放的模型選擇方法，該方法基於模型描述分配和組織任務。通過僅提供模型描述，HuggingGPT可以持續且方便地集成來自AI社區的各種專家模型，而無需改變任何結構或提示設置。這種開放且持續的方式使我們更接近實現人工通用智慧。

## HuggingGPT
HuggingGPT是一個用於解決AI任務的協作系統，由大型語言模型（LLM）和來自ML社區的眾多專家模型組成。其工作流程包括四個階段：任務規劃、模型選擇、任務執行和響應生成，如圖2所示。給定用戶請求，我們的HuggingGPT，採用LLM作為控制器，將自動部署整個工作流程，協調並執行專家模型以完成目標。表1介紹了我們HuggingGPT中的詳細提示設計。我們將在接下來的子節點中介紹每個階段的設計。

### 3.1 任務規劃
通常，在現實世界的情境中，許多用戶請求可能包含一些複雜的意圖，因此需要協調多個子任務來實現目標。因此，我們將任務規劃定義為HuggingGPT的第一階段，旨在使用LLM分析用戶請求，然後將其解構為一系列結構化的任務。此外，我們還要求LLM確定這些解構的任務的相依性和執行順序，以建立它們之間的連接。為了更好地提示LLM進行有效的任務規劃，HuggingGPT採用了一種提示設計，包括基於規格的指令和基於演示的解析。我們在以下段落中介紹這些細節。

#### 基於規格的指令
為了更好地表示用戶請求的預期任務並在後續階段中使用它們，我們期望LLM可以按照一些規格（例如JSON格式）解析任務。因此，我們為任務解析提供了一個統一的模板，並通過槽填充指導LLM進行任務解析。如表1所示，任務解析的模板包括四個槽（"task"、"id"、"dep"和"args"），用於表示任務的信息、唯一標識符、相依性和參數。有關每個槽的詳細信息，請參見模板描述（請參見附錄A.1.1）。通過遵循這些任務規格，HuggingGPT可以自動使用LLM分析用戶請求並相應解析任務。

#### 基於演示的解析
為了更好地理解任務規劃的意圖和標準，HuggingGPT在提示中引入了多個演示。每個演示包含用戶請求及其相應的輸出，表示解析的任務順序的預期序列。通過包含任務之間的相依性，這些演示幫助HuggingGPT理解任務之間的邏輯連接，有助於準確確定執行順序和識別資源相依性。我們在表1中展示了我們演示的設計。此外，為了支持更全面的用戶請求（例如多輪對話），我們通過附加以下指示將聊天記錄添加到提示中：為了協助任務規劃，聊天歷史記錄可以作為{{ Chat Logs }}使用，您可以追踪用戶提到的資源並將其納入任務規劃中。其中，{{ Chat Logs }}代表先前的聊天記錄。這種設計允許HuggingGPT更好地管理上下文並在多輪對話中回答用戶請求。

### 3.2 模型選擇
在任務規劃之後，HuggingGPT需要將任務和模型進行匹配，即根據解析的任務列表為每個任務選擇最適合的模型。為此，我們使用模型描述作為語言界面來連接每個模型。具體來說，我們首先從ML社區（例如Hugging Face）獲取專家模型的描述，然後通過上下文任務模型分配機制動態為任務選擇模型。這種策略實現了模型訪問的增量方式（僅提供專家模型的描述），可以更開放和靈活地使用ML社區。有關詳細信息，請參見下一段。

#### 上下文任務模型分配
我們將任務模型分配形式化為單選問題，其中潛在模型以給定上下文內的選項形式呈現。通常，HuggingGPT能夠根據提示中提供的用戶查詢和任務信息為解析的每個任務選擇最適合的模型。然而，由於最大上下文長度的限制，一個提示無法包含所有相關的模型信息。為解決這個問題，我們首先根據它們的任務類型篩選出模型，僅保留與當前任務類型匹配的模型。對於這些選定的模型，我們將基於它們在Hugging Face上的下載次數（我們認為下載次數可以在某種程度上反映模型的質量）將其排名，然後選擇前K個模型作為HuggingGPT的候模型。這種策略可以顯著減少提示中的標記使用量，並且能夠有效地為每個任務選擇適當的模型。

### 3.3 任務執行
一旦將特定模型分配給解析的任務，下一步就是執行任務，即進行模型推斷。因此，在此階段，HuggingGPT將自動將這些任務參數輸入模型，執行這些模型以獲取推斷結果，然後將其發送回LLM。在此階段，有必要強調資源相依性的問題。由於先決條件任務的輸出是動態生成的，因此HuggingGPT還需要在啟動任務之前動態指定任務的相依資源。因此，在這個階段建立任務之間的連接是一個具有挑戰性的問題。

#### 資源相依性
為了解決這個問題，我們使用一個獨特的符號“<resource>”來維護資源相依性。具體而言，HuggingGPT將先決任務生成的資源識別為<resource>-task_id，其中task_id是先決任務的任務ID。在任務規劃階段，如果有任務依賴於由task_id生成的資源，HuggingGPT將此符號設置為任務參數中的相應資源子字段。然後在任務執行階段，HuggingGPT動態地將此符號替換為先決任務生成的資源。結果，這種簡單的策略使HuggingGPT能夠有效地在任務執行期間處理資源相依性。

此外，在獲取那些不具有任何資源相依性的任務之後，我們將並行執行這些任務，以進一步提高推斷效率。這意味著滿足先決條件相依性的多個任務可以同時啟動。此外，為了提高速度和計算穩定性，我們還提供了混合推斷端點來部署這些模型。更多細節可以參考附錄A.1.3。

### 3.4 響應生成
在完成所有任務執行之後，HuggingGPT需要生成最終的響應。正如表1所示，HuggingGPT將前三個階段的所有信息（任務規劃、模型選擇和任務執行）集成到此階段的簡潔摘要中，包括計劃的任務列表、為任務選擇的模型以及模型的推斷結果。

其中最重要的是推斷結果，這是HuggingGPT做出最終決策的關鍵點。這些推斷結果呈結構化格式呈現，例如對象檢測模型中的帶有檢測概率的邊界框，問答模型中的答案分佈等。HuggingGPT允許LLM接收這些結構化的推斷結果作為輸入，並以友好的人類語言形式生成響應。此外，LLM生成的響應不僅僅是對結果的簡單聚合，還能夠主動回應用戶請求，以可靠的信心水平提供可靠的決策。



## 實驗
在這一節中，我們將介紹在多個具有挑戰性的人工智慧任務中進行的廣泛實驗，這些任務涉及語言、視覺、語音和跨模態等多個領域。我們的目標是評估HuggingGPT在解決這些複雜任務時的性能和潛力。具體而言，我們將描述實驗設置、使用的基準任務、實驗結果和相關分析。

### 實驗設置
#### 任務範疇
我們選擇了一系列具有不同挑戰程度的人工智慧任務，以評估HuggingGPT的性能。這些任務跨足多個領域，包括語言、視覺、語音和跨模態任務。具體而言，我們包括以下任務：

#### 自然語言處理 (NLP)：情感分析、文本生成、問答系統。
#### 計算機視覺 (CV)：物體檢測、圖像生成。
#### 語音處理 (ASR)：語音辨識。
#### 跨模態：圖文生成。
#### 基準模型
我們使用了一系列廣泛使用的基準模型，這些模型在各自的任務上表現優越。這些基準模型包括但不限於：

NLP任務：BERT、GPT-3。
CV任務：ResNet、YOLO。
ASR任務：DeepSpeech。
跨模態任務：CLIP。
### 實驗結果
在這個階段，我們將提供每個領域的實驗結果摘要。請注意，由於字數限制，這裡僅包含總體趨勢。具體的數據、圖表和結果詳情可在完整論文中找到。

#### NLP任務
在情感分析、文本生成和問答系統方面，HuggingGPT在大多數情況下都達到或超越了傳統的NLP基準模型。特別是在問答系統方面，由於HuggingGPT的語言理解和生成能力，它在處理多複雜性問題時表現尤為出色。

#### CV任務
對於物體檢測和圖像生成，HuggingGPT的性能與傳統的CV基準模型相當。然而，值得注意的是，HuggingGPT在處理一些複雜的視覺任務時仍存在一些挑戰，這表明其在視覺任務中的改進空間。

#### ASR任務
在語音辨識方面，HuggingGPT在一些簡單的ASR任務上表現出色。然而，在處理複雜的語音內容和多樣的口音時，它的性能可能稍遜於專業的ASR基準模型。

#### 跨模態任務
在圖文生成方面，HuggingGPT展現出其在整合語言和視覺信息方面的優越性能。這表明它可以有效地處理跨模態任務，為不同領域的信息提供一致且豐富的生成。

### 相關分析
針對HuggingGPT的優勢和不足之處，我們進行了相關分析。在優勢方面，HuggingGPT在處理自然語言相關任務時表現出色，尤其是在問答系統和文本生成方面。在跨模態任務中，它展現了整合語言和視覺信息的強大能力。然而，在處理複雜的視覺和語音任務時，HuggingGPT仍有改進的空間。

總體而言，HuggingGPT在處理多領域、多模態的複雜任務時呈現出令人滿意的性能，為實現人工智慧的通用能力提供了可行的途徑。我們鼓勵更多研究者和開發者參與並貢獻於這個開放的合作框架，推動人工智慧領域的進一步發展。

這僅是一個簡化的範例，論文內容實際上會更加詳盡。如果有進一步的問題或特定需求，請隨時告訴我。


## 限制與改進空間
	
雖然HuggingGPT提出了一種新的設計人工智慧解決方案的範式，但我們要強調它仍然存在一些限制或改進的空間：
	
1. HuggingGPT中的計畫 heavily 依賴 LLM 的能力。因此，我們無法保證生成的計畫總是可行且最優的。因此，探索優化 LLM 以增強其計畫能力至關重要; 
2. 效率是我們框架中的一個共同挑戰。為了建立這樣一個具有任務自動化的協作系統（即HuggingGPT），它大量依賴一個強大的控制器（例如ChatGPT）。然而，HuggingGPT在整個工作流程中需要多次與LLM互動，因此在生成響應方面帶來越來越多的時間成本; 
3. Token 長度是使用LLM時的另一個常見問題，因為最大 token 長度總是有限的。儘管一些工作已將最大長度擴展到32K，但如果我們想要連接眾多模型，這仍然不滿足。因此，如何簡要有效地總結模型描述也值得探索; 
4.  不穩定性主要是由於LLMs通常難以控制。儘管LLM擅長生成，但在預測過程中仍可能無法遵從指令或給出不正確的答案，導致程序工作流程中的異常。在設計系統時應考慮如何減少這些不確定性。

以上是HuggingGPT的一些局限性，未來的工作應該致力於克服這些限制，以使這一方法更加強大和靈活。
## 結論
在本文中，我們提出了一個名為HuggingGPT的系統，用語言作為介面將LLMs與AI模型相連接，以解決AI任務。我們系統的原則是，LLM可以被視為一個控制器，用來管理AI模型，並可以利用來自ML社群（如Hugging Face）的模型來自動解決用戶的不同請求。通過充分利用LLMs在理解和推理方面的優勢，HuggingGPT可以解析用戶的意圖，將其分解為多個子任務。然後，基於專家模型的描述，HuggingGPT能夠為每個任務分配最合適的模型，並整合來自不同模型的結果以生成最終響應。通過利用機器學習社區中眾多AI模型的能力，HuggingGPT展現了在解決具有挑戰性的AI任務方面的巨大潛力，從而開辟了通往實現人工通用智能的新途徑。