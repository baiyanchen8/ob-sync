---
title: Support Vector Machine
tags: [機器學習]

---

# Support Vector Machine

## 介紹
支援向量機（SVM）不僅用於分類問題，還可用於迴歸問題。 核函數在SVM和SVR中扮演關鍵角色，將無法在<font color ="ffff">低維度處理的數據向高維度轉換</font>，以此細化數據。

## 支援向量機（SVM）重要概念

### Margin（間隔）
- define 

    間隔是指支持向量與決策邊界之間的距離。SVM的目標是最大化這個間隔，因為更大的間隔通常表示更好的泛化效能。
- soft Margin

    指的是可以一定程度容忍錯誤和極端值，以達到對normal case更好的效果
- Maximal Margin Classifier(hard Margin)

    與soft Margin不同，Maximal Margin Classifier<font color="ffff">不容忍錯誤</font>，只是單純選擇兩個Data中的中間點
    ![](rkXdrhUfp.png)

### 支援向量
支持向量是與決策邊界最靠近的資料點。 它們在SVM的訓練過程中起著關鍵作用，因為它們決定了間隔的大小。

## 支援向量迴歸（SVR）

### SVR概述
支持向量回歸（SVR）用於解決回歸問題。 與分類問題不同，迴歸問題的目標變數是連續的。

### SVR工作原理
1. 資料準備：與分類一樣，SVR從一個資料集開始，但目標變數是連續值。
2. 特徵縮放：尺度變換對於SVR很重要，因為它對變數的尺度敏感。 常用的技術包括標準化或正規化。
3. 模型選擇：在SVR中，您必須選擇一個核函數。 核函數的選擇決定了資料的轉換方式。

## 核函數（Kernel Function）

### 核函數概述
核函數是SVM和SVR中的關鍵元素。 它們用於將資料從原始特徵空間轉換為高維特徵空間，使得演算法能夠更好地處理非線性關係。

### 常見的核函數
1. **線性核函數（Linear Kernel）**：用於處理線性關係，直接進行點積運算。
2. **多項式核函數（Polynomial Kernel）**：處理多項式關係，透過升高特徵到高維度空間來建模資料

    $(a\times b)^r$
3. **徑向基底函數（Radial Basis Function，RBF）**：用於捕捉複雜的非線性關係，是最常用的核函數之一。

    $e^{-r(a-b)^2}$
### 核函數參數
不同的核函數可能有特定的參數，如多項式核函數的階數或徑向基底函數的頻寬。 調整這些參數可以影響模型的效能。

## 結論

支持向量迴歸（SVR）是一種迴歸技術，允許處理線性和非線性關係，核函數在這個過程中起著重要作用。 核函數選擇和參數調整可以對SVM和SVR的性能產生重大影響，因此這是使用這些演算法時需要特別關注的領域。